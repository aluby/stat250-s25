---
title: "CLT-based Confidence Intervals"
subtitle: "Day 16"
title-slide-attributes:
  data-background-gradient: "linear-gradient(to right, #46337e, #440154)"
  data-slide-number: none
author: "Prof Amanda Luby"
format: 
  revealjs:
    incremental: false
editor: 
  markdown: 
    wrap: 72
---

```{r setup}
#| include: false

library(tidyverse)
library(countdown)

library(ggformula)
library(openintro)
library(patchwork)
library(fivethirtyeight)
library(dplyr)
library(tidyr)
library(fontawesome)
library(gt)

library(gridExtra)
library(tidyverse)
library(knitr)
library(mosaic)
library(infer)
library(kableExtra)
library(latex2exp)

library(plotly)

# #440154
knitr::opts_chunk$set(echo = TRUE,
                  message = FALSE,
                  warning = FALSE)

slides_theme = theme_minimal(base_family = "serif", base_size = 16) +
  theme(plot.background = element_rect(fill = "#f0f1eb", colour = NA))
  

theme_set(slides_theme)
```

## Goal: develop an **interval estimate** of a population parameter {.center}

## 

**Example:** Suppose we observe $X_1, ..., X_n$ , which represent the error rates of $n$ different forensic examiners. I am interested in finding a confidence interval for $\mu$, the average error rate in the population. We have a sample of size 30 shown below:

```{r}
#| echo: false

lp_results <- read_delim("https://www.fbi.gov/file-repository/laboratory/testresponses.txt/@@download/file/TestResponses.txt", delim = "\t")

set.seed(0507)
examiner_error_rates <- lp_results |>
  mutate(
    error = case_when(
      Compare_Value == "Exclusion" & Mating == "Mates" ~ 1,
      Compare_Value == "Individualization" & Mating == "Non-mates" ~ 1,
      is.na(Latent_Value) ~ NA,
      TRUE ~ 0
    )
  ) |>
  group_by(Examiner_ID) |>
  summarize(
    error_rate = mean(error)
  )  |>
  slice_sample(n=30)

ggplot(examiner_error_rates, aes(x = error_rate)) + 
  geom_histogram(bins = 12, col = "white")

examiner_error_rates |>
  summarize(
    mean = mean(error_rate),
    sd = sd(error_rate),
    n = n()
  ) |>
  round(digits = 4) |>
  knitr::kable()
```

## Let's review our confidence interval toolkit so far:

1.  Construct a bootstrap distribution and find a **percentile-based** confidence interval

2.  Either (a) assume a normal population or (b) use the CLT to construct a **formula t-based** confidence interval

3.  Assume a different population distribution and construct a **pivot-based** confidence interval

## Bootstrap percentile interval

```{r}
error_rates <- examiner_error_rates$error_rate
n = length(error_rates)
N = 10^4
boot_means = numeric(N)

for(i in 1:N){
  x <- sample(error_rates, size = n, replace = TRUE)
  boot_means[i] <- mean(x, na.rm = TRUE)
}

quantile(boot_means, probs = c(.025, .975))
```

## CLT-based t confidence interval

```{r}
#| echo: true 

qt(.975, df = 29)
```

## CLT-based t confidence interval

Can also use a built-in R function:

```{r}
#| echo: true 

t.test(error_rates, conf.level = .95)$conf
```

**When do we trust this confidence interval?**

## Look at bootstrap T*

```{r}
#| echo: true
t_star <- numeric(N)

for(i in 1:N){
  x <- sample(error_rates, size = n, replace = TRUE)
  t_star[i] <- (mean(x) - mean(error_rates))/(sd(x)/sqrt(n))
}

```

```{r}
#| echo: false
p1 <- ggplot() + 
  geom_histogram(bins = 12, col = "white", aes(x = t_star)) + 
  labs(
    title = "Distribution of T*"
  )

p2 <- ggplot() + 
  geom_qq(aes(sample = t_star), distribution = qt, dparams = 29) + 
  geom_qq_line(aes(sample = t_star), distribution = qt, dparams = 29)  + 
  labs(
    title = "QQ of T*",
    subtitle = "Compared to theoretical t(29)"
  )

p1 + p2
```

## Issues

-   Distribution of $T*$ is slightly **left-skewed**
-   Tails of $T*$ don't seem to match the theoretical t

## Why does this happen?

```{r}
#| echo: false


boot_mean <- numeric(N)
boot_sd <- numeric(N)
t_star <- numeric(N)
for(i in 1:N){
  x <- sample(error_rates, size = n, replace = TRUE)
  boot_mean[i] <- mean(x)
  boot_sd[i] <- sd(x)
  t_star[i] <- (mean(x) - mean(error_rates))/(sd(x)/sqrt(n))
}

limit <- max(abs(t_star)) * c(-1, 1)

ggplot() + 
  geom_point(aes(x = boot_mean, y = boot_sd, col = t_star)) +
  scale_color_distiller(type = "div", limit = max(abs(t_star) -1) * c(-1, 1)) +
  theme(panel.background = element_rect(fill = "gray25"))
```

## Bootstrap t confidence interval 

The CLT-based confidence interval relies on:

$$1-\alpha = P(t_{\alpha/2} < \frac{\bar{X} - \mu}{s/\sqrt{n}} < t_{1-\alpha/2})$$

**Idea:** generate "better" quantiles using the bootstrap distribution:

## Then solve for $\mu$:



## to obtain the bootstrap $t$ confidence interval:


::: aside
::: callout-warning
## Watch out!

Lower bound is computed from the **upper** percentile and upper bound is computed from the **lower** percentile
:::
:::

## Bootstrap T algorithm

::: callout-note
## Bootstrap T algorithm

1.  Repeat the bootstrap procedure many times:
    -   Take bootstrap sample
    -   Compute mean ($\bar{X}^*$) and sd ($s^*$) of each bootstrap sample
    -   Compute t-statistic for each bootstrap sample: $T^* = \frac{\bar{X}^* - \bar{X}}{s^*/\sqrt{n}}$
2.  Find quantiles $Q_{\alpha/2}^*$ and $Q_{1-\alpha/2}^*$ using distribution of $T^*$
3.  Compute confidence interval using the bootstrap t quantiles: $$(\bar{x} - Q^*_{1-\alpha/2}\frac{s}{\sqrt{n}}, \bar{x} - Q^*_{\alpha/2}\frac{s}{\sqrt{n}})$$
:::

## Example: bootstrap t for error rates

```{r}
#| echo: true 
n = length(error_rates)
N = 10^4
boot_means <- numeric(N)
boot_tstar <- numeric(N)
for(i in 1:N){
  x <- sample(error_rates, size = n, replace = TRUE)
  boot_means[i] <- mean(x)
  t_star[i] <- (mean(x) - mean(error_rates))/(sd(x)/sqrt(n))
}

quantile(t_star, probs = c(.025, .975))
mean(error_rates) - quantile(t_star, probs = c(.025, .975))*sd(error_rates)/sqrt(n)
```

## Summary of results 

|                      | Lower | Upper |
|----------------------|-------|-------|
| Percentile Bootstrap | .021  | .0458  |
| CLT t-based          | .020  | .0453  |
| Bootstrap t          | .022  | .0509  |

## R Activity

The {nycflights23} R package contains a dataset called `flights`. This dataset contains all flights in and out of NYC-area airports in 2023. Since the dataset has **all** flights, we can treat it as a population. We're interested in the average **departure delay** of **flights departing from NYC area airports**. 

We'll explore the performance of our different confidence interval procedures. To do so, you'll first draw a *sample* from the `flights` dataset. You'll treat this as your data sample throughout the rest of the activity, and compare your confidence intervals to the true value from the whole dataset.

## Results

## 

![](../img/flights-coverage-plot.png)
