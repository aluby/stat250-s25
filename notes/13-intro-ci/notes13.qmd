---
title: "13: Intro to the Bootstrap"
author: "Prof Amanda Luby"
subtitle: "Stat250 S25"
callout-appearance: minimal
knitr:
    opts_chunk: 
      dev: "ragg_png"
      echo: false
      warning: false
      message: false
format:
  pdf:
    include-in-header: 
       - "../preamble.tex"
    toc: false
    number-sections: true
    colorlinks: true
    geometry:
      - top=1in
      - left=1in
      - right=1in
      - bottom=1in
      - heightrounded
    mainfont: "Linux Libertine"
    sansfont: "Linux Libertine"
    mathfont: "Libertinus Math"
    monofont: "Monaco"
fontsize: 11pt
---

```{r}
library(tidyverse)
library(ggformula)
library(knitr)
library(mosaic)
library(patchwork)
data("penguins", package = "palmerpenguins")
gentoo <- filter(penguins, species == "Gentoo")
theme_set(theme_minimal())
```

# Roadmap

Observe $X_1, ..., X_n \sim F(\theta)$ with $\theta$ unknown. Estimate $\hat\theta = g(X_i)$. 

Do we expect $\hat\theta$ to be **exactly equal** to $\theta$?

What are **plausible values** for $\theta$ given an observed $\hat\theta$?

We want to develop an interval estimate of a population parameter: 

1. *Exact method:* Find the sampling distribution in closed form (Ch 4). REquires knowledge of the distribution of the data
2. **Bootstrap Method:** Use the sample to approximate the population and simulate a sampling distribution (Ch5)
3. *Asymptotic method:* Use large-sample theory to approximate the sampling distribution (e.g., appeal to the CLT; Ch7)

# Example: gentoo penguin bill length

```{r fig.height = 2, fig.width = 3, echo=FALSE, warning=FALSE, out.width="55%", fig.align='left'}
#| layout-ncol: 2


gf_histogram(~bill_length_mm, data = gentoo, xlab = "Bill length (mm)") 
favstats(~bill_length_mm, data = gentoo) %>% t() %>% kable(digits = 2)
```

## The one-sample bootstrap algorithm

Given a sample of size *n* from a population,

1.  Draw a resample of size *n*, **with replacement**, from the sample.

2.  Compute the statistic of interest.

3.  Repeat this resampling process (steps 1-2) many times, say 10,000.

4.  Construct the bootstrap distribution of the statistic.

# How does the bootstrap work?

```{r}
set.seed(1234)
sample_data <- rgamma(50, 2, 2)

p1 <- gf_function(fun = dgamma, args = list(shape = 2, rate = 2), xlim = c(0, 5)) +
  labs(y = "f(x)",
       title = "Population") +
  geom_vline(xintercept = 1, color = "blue", size = 1.1)

p2 <- gf_histogram(~sample_data, binwidth = 0.5, color = "gray30", xlab = "x") +
  scale_x_continuous(breaks = seq(0, 5, 1)) +
  labs(title = "Sample") + 
  geom_vline(xintercept = mean(sample_data), color = "yellow", size = 1.1, linetype = "dashed")  

pop_sim <- replicate(10000, rgamma(50, 2, 2))
sampling_dsn <- apply(pop_sim, 2, mean)

boot_sim <- replicate(10000, sample(sample_data, replace = TRUE))
boot_dsn <- apply(boot_sim, 2, mean)

p3 <- gf_histogram(~boot_dsn, bins = 30, xlim = range(boot_dsn), 
             xlab = "bootstrap means", color = "gray30") %>%
  gf_vline(xintercept = ~mean(~boot_dsn), color = "yellow", size = 1.1, linetype = "dashed")  + 
  labs(title = "Bootstrap dist")


p4 <- gf_histogram(~sampling_dsn, bins = 30, xlim = range(boot_dsn), 
             xlab = "sample means", color = "gray30",) %>%
  gf_vline(xintercept = ~mean(~sampling_dsn), color = "blue", size = 1.1) + 
  labs(title = "Sampling dist")

p1 + p2 + p4 + p3
```

|   | Mean | SD | Bias |
|------------------------|----------------|----------------|----------------|
| Population | 1 | 0.5 |  |
| Sample |  | |  |
| Sampling distribution |  |  |  |
| Bootstrap distribution | | ||

# Why does the bootstrap work?

First, recall the definition of the CDF: 

$$F_x(x_0) = P(X \le x_0)$$


In other words, $F_x$ is the probability of the event $\{X \le x_0\}$. If we observe a sample of $X_1, ..., X_n \sim F_x$, a natural estimator for this probability is the observed proportion of observations where $\{X_i \le x_0\}$. 


$$\widehat F_n = \frac{\sum \mathbb{I}(X_i \le x_0)}{n}$$

so __________ is an estimator for _________

Each bootstrap sample is drawn from $\widehat F$: 

\pagebreak 

$X_1^{*(1)}, X_2^{*(1)}, ... X_n^{*(1)} \sim \widehat F_n$



As n increases, $\widehat{F}_n$ gets closer to true $F$

```{r}
#| fig-height: 2
#| fig-width: 6
#| echo: false

ecdf_10 = ecdf(rnorm(10))
ecdf_100 = ecdf(rnorm(100))
ecdf_1000 = ecdf(rnorm(1000))

p1 =   tibble(
    x = seq(-3, 3, by = .1),
    y = ecdf_10(x)
  ) %>%
  ggplot(aes(x = x, y = y)) + 
  geom_line() + 
  stat_function(
    fun = pnorm, 
    col = 'darkorange'
  ) + 
  labs(
    x = "x",
    y = expression(F[x]),
    title = "n = 10"
  )

p2 =   tibble(
    x = seq(-3, 3, by = .1),
    y = ecdf_100(x)
  ) %>%
  ggplot(aes(x = x, y = y)) + 
  geom_line() + 
  stat_function(
    fun = pnorm, 
    col = 'darkorange'
  ) + 
  labs(
    x = "x",
    y = expression(F[x]),
    title = "n = 100"
  )
  
p3 =   tibble(
    x = seq(-3, 3, by = .1),
    y = ecdf_1000(x)
  ) %>%
  ggplot(aes(x = x, y = y)) + 
  geom_line() + 
  stat_function(
    fun = pnorm, 
    col = 'darkorange'
  ) + 
  labs(
    x = "x",
    y = expression(F[x]),
    title = "n = 1000"
  )

p1 + p2 + p3
```

It turns out that $\widehat{F}_n$ is an _____________________ and  _____________________ estimator for $F$! 

- When $n$ is large, $\widehat{F}_n$ is very close to $F$
- So any statistic that is based on $\widehat{F}_n$ is very similar to the same statistic based on $F$
- Re-sampling from our original sample results in a sampling distribution that is very similar to the theoretical sampling distribution 
- This is true even if we don't know what the theoretical sampling distribution is! 

# R Implementation

```{r}
gentoo <- dplyr::filter(penguins, species == "Gentoo")
```
```{r}
#| echo: true
y <- gentoo$bill_length_mm # original sample
n <- nrow(gentoo)          # sample size
N <- 10^4                  # desired no. resamples
boot_means <- numeric(N)   # a place to store the bootstrap stats

# Resampling from the sample
for (i in 1:N) {
  x <- sample(y, size = n, replace = TRUE)
  boot_means[i] <- mean(x, na.rm = TRUE)  # you can choose other statistics
}
# Calculate a 95% percentile interval
quantile(boot_means, probs = c(0.025, 0.975))
```
